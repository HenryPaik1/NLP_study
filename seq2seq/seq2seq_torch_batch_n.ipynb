{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code\n",
    "- make dataset\n",
    "- train\n",
    "- evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# reference: https://github.com/pengyuchen/PyTorch-Batch-Seq2seq/blob/master/seq2seq_translation_tutorial.py\n",
    "\n",
    "import unicodedata\n",
    "import re\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "class saveLang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: 'PAD'}\n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "\n",
    "    def update_voc_dict(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            if word not in self.word2index:\n",
    "                self.word2index[word] = self.n_words\n",
    "                self.word2count[word] = 1\n",
    "                self.index2word[self.n_words] = word\n",
    "                self.n_words += 1\n",
    "            else:\n",
    "                self.word2count[word] += 1\n",
    "\n",
    "def _make_pair(lang1, lang2, reverse=False):\n",
    "    #lines = open('%s-%s.txt' % (lang1, lang2), encoding='utf-8').read().strip().split('\\n')\n",
    "    # toy dataset\n",
    "    lines = ['j a l f h z z\\tz z h f l a j', 'j y w a r e d v\\tv d e r a w y j', 'o c q u c w\\tw c u q c o', 'l q\\tq l', 'b z g b c\\tc b g z b', 'p l\\tl p', 'p o n j d u u c r p\\tp r c u u d j n o p', 'm m l p r j d\\td j r p l m m', 'k b s f l u n p\\tp n u l f s b k', 'r a o i d d s a k\\tk a s d d i o a r', 'u n p r q\\tq r p n u', 'w\\tw', 'h h x i d c z w j p\\tp j w z c d i x h h', 'u\\tu', 'f\\tf', 'o o l u w h z u j\\tj u z h w u l o o', 'h v k p y n d j a\\ta j d n y p k v h', 'j f u v u\\tu v u f j', 'l n m u\\tu m n l', 'j\\tj', 'w h\\th w', 's l r w z r l y\\ty l r z w r l s', 'r c b r u k x i q\\tq i x k u r b c r', 'u u d q t m y i c v\\tv c i y m t q d u u', 'w i m v v r\\tr v v m i w', 'a f z e\\te z f a', 'y x k x c\\tc x k x y', 'f k z n s c v b b\\tb b v c s n z k f', 'o g\\tg o', 'j c m d b\\tb d m c j', 'p t k v f v a f\\tf a v f v k t p', 'b t\\tt b', 'a z q l i l\\tl i l q z a', 'm a q a t\\tt a q a m', 'd e l q t t\\tt t q l e d', 'g g h x j i x\\tx i j x h g g', 'a u a y l\\tl y a u a', 'g c g o h q i c\\tc i q h o g c g', 'w f h c a z l\\tl z a c h f w', 'e\\te', 'y h\\th y', 'a t i t m k r q\\tq r k m t i t a', 'l s\\ts l', 'l t u v n n v\\tv n n v u t l', 'b x c c t s x w r q\\tq r w x s t c c x b', 'c o o x j d d r z\\tz r d d j x o o c', 'e g z k q i d\\td i q k z g e', 'v n u o\\to u n v', 'u f g i d c q x g\\tg x q c d i g f u', 'x z p r j z l y\\ty l z j r p z x', 'b h c\\tc h b', 'a u\\tu a', 'y v z q j p b l f s\\ts f l b p j q z v y', 'm q f j u v h p d u\\tu d p h v u j f q m', 'q c f b p k w v p\\tp v w k p b f c q', 't u\\tu t', 'q y v i g x j s\\ts j x g i v y q', 'b r u t m m\\tm m t u r b', 'c b n c i g b v\\tv b g i c n b c', 'd j d v a\\ta v d j d', 'e v\\tv e', 'd q n r y h i\\ti h y r n q d', 'q i x d e f c\\tc f e d x i q', 'f g p\\tp g f', 'f b v w\\tw v b f', 'k f n u s u q\\tq u s u n f k', 'p l c f h i\\ti h f c l p', 'c m p\\tp m c', 'f k r k p d c z\\tz c d p k r k f', 'f y s f n m d x i x\\tx i x d m n f s y f', 'f z g f h a q d w\\tw d q a h f g z f', 'l l z g o j j j v\\tv j j j o g z l l', 'j r\\tr j', 'a t e f a o y c\\tc y o a f e t a', 'z i m i u r v n t g\\tg t n v r u i m i z', 'i p c v y q\\tq y v c p i', 'a r s t n f l i\\ti l f n t s r a', 'v i r w u l h n d\\td n h l u w r i v', 'h c r m c h x j d b\\tb d j x h c m r c h', 'u c t\\tt c u', 'n\\tn', 'i s q x i a u s m u\\tu m s u a i x q s i', 't r d d\\td d r t', 'l t k v n j k\\tk j n v k t l', 'i q\\tq i', 'e b y a e k r f m\\tm f r k e a y b e', 'l y o x a\\ta x o y l', 'f m c v s m u q\\tq u m s v c m f', 'e w y c l y q\\tq y l c y w e', 'b w\\tw b', 'j j f a a n\\tn a a f j j', 'a u c z f e\\te f z c u a', 'k m a j\\tj a m k', 'm t j p a\\ta p j t m', 'j n p s c\\tc s p n j', 'g n n t x s o\\to s x t n n g', 'q f h p e h\\th e p h f q', 'q j x\\tx j q', 'b s\\ts b', 'm h g i\\ti g h m']\n",
    "    pairs = [[s for s in l.split('\\t')] for l in lines]\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = saveLang(lang2)\n",
    "        output_lang = saveLang(lang1)\n",
    "    else:\n",
    "        input_lang = saveLang(lang1)\n",
    "        output_lang = saveLang(lang2)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def make_dataset(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = _make_pair(lang1, lang2, reverse)\n",
    "    for pair in pairs:\n",
    "        input_lang.update_voc_dict(pair[0])\n",
    "        output_lang.update_voc_dict(pair[1])\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "def _sen2idx(lang, sentence, time_step):\n",
    "    idxs = [lang.word2index[word] for word in sentence.split(' ')][:time_step]\n",
    "    idxs.append(EOS_token)\n",
    "    idxs.extend([PAD_token] * (time_step - len(idxs)))\n",
    "    result = torch.LongTensor(idxs)\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "def pairs2idx(input_lang, output_lang, pairs, time_step):\n",
    "    dataset = []\n",
    "    for pair in pairs:\n",
    "        input_variable = _sen2idx(input_lang, pair[0], time_step)\n",
    "        target_variable = _sen2idx(output_lang, pair[1], time_step)\n",
    "        dataset.append((input_variable, target_variable))\n",
    "    return dataset\n",
    "\n",
    "# time step should be long enough\n",
    "time_step = 50\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "\n",
    "input_lang, output_lang, pairs = make_dataset('eng', 'kor',  reverse=False)\n",
    "pairs = pairs2idx(input_lang, output_lang, pairs, time_step)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, voc_size, embed_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(voc_size, embed_size)\n",
    "        self.embedding.weight.data.copy_(torch.eye(voc_size, embed_size))\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        \n",
    "        self.gru = nn.GRU(embed_size, hidden_size)\n",
    "\n",
    "    def forward(self, input_data, batch_size, hidden):\n",
    "        embed = self.embedding(input_data).view(1, batch_size, self.embed_size)\n",
    "        output = embed\n",
    "        # reference: https://discuss.pytorch.org/t/clarification-regarding-the-return-of-nn-gru/47363\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def first_hidden(self, batch_size):\n",
    "        val =  Variable(torch.zeros(1, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return val.cuda()\n",
    "        else:\n",
    "            return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, voc_size, embed_size, hidden_size,):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(voc_size, embed_size)\n",
    "        self.embedding.weight.data.copy_(torch.eye(voc_size, embed_size))\n",
    "        self.embedding.weight.requires_grad = True\n",
    "        \n",
    "        self.gru = nn.GRU(embed_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, voc_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_data, batch_size, hidden):\n",
    "        embed = self.embedding(input_data).view(1, batch_size, self.embed_size)\n",
    "        output = embed\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.out(output) # shape: [1, batch_size, voc_size]\n",
    "        output = self.softmax(output[0])\n",
    "        return output, hidden\n",
    "    \n",
    "    def first_hidden(self, batch_size):\n",
    "        val =  Variable(torch.zeros(1, batch_size, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return val.cuda()\n",
    "        else:\n",
    "            return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "PAD_token = 2\n",
    "\n",
    "teacher_forcing_ratio = 0.5\n",
    "embed_size = 100\n",
    "hidden_size = 30 #a-z+SOS+EOS+PAD\n",
    "batch_size = 20\n",
    "epochs = 1\n",
    "\n",
    "encoder = Encoder(voc_size=input_lang.n_words, embed_size=embed_size, hidden_size=hidden_size)\n",
    "decoder = Decoder(voc_size=input_lang.n_words, embed_size=embed_size, hidden_size=hidden_size)\n",
    "\n",
    "use_cuda = False\n",
    "\n",
    "if use_cuda:\n",
    "    encoder = encoder.cuda()\n",
    "    decoder = decoder.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_train(input_variable, target_variable, encoder, decoder, encoder_optim, decoder_optim, criterion, time_step, teacher_forcing_ratio):\n",
    "    \n",
    "    # encoder part\n",
    "    batch_size = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.first_hidden(batch_size)\n",
    "    \n",
    "    # input_variable: [batch_size, n_time_step]\n",
    "    # input_variable.transpose: [n_time_step, batch_size]\n",
    "    input_variable = Variable(input_variable.transpose(0, 1))\n",
    "    encoder_optim.zero_grad()\n",
    "    en_time_step = input_variable.size()[0]\n",
    "    \n",
    "    loss = 0\n",
    "    encoder_outputs = Variable(torch.zeros(time_step, batch_size, encoder.hidden_size))\n",
    "    for i in range(en_time_step):\n",
    "        en_output, en_hidden = encoder(input_variable[i], batch_size, encoder_hidden)\n",
    "        encoder_outputs[i] = en_output # ???????\n",
    "    \n",
    "    # decoder part\n",
    "    # first input: SOS token\n",
    "    target_variable = Variable(target_variable.transpose(0, 1))\n",
    "    decoder_optim.zero_grad()\n",
    "    de_time_step = target_variable.size()[0]\n",
    "    \n",
    "    decoder_input = Variable(torch.LongTensor([SOS_token] * batch_size))\n",
    "    de_hidden = en_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for i in range(de_time_step):\n",
    "            de_out, de_hidden = decoder(decoder_input, batch_size, de_hidden)\n",
    "            loss += criterion(de_out, target_variable[i])\n",
    "            decoder_input = target_variable[i]\n",
    "            \n",
    "    else:\n",
    "        for i in range(de_time_step):\n",
    "            de_out, de_hidden = decoder(decoder_input, batch_size, de_hidden)\n",
    "            loss += criterion(de_out, target_variable[i])\n",
    "            \n",
    "            topv, topi = de_out.data.topk(1) # topi: voc_idx\n",
    "            decoder_input = Variable(torch.flatten(topi)) \n",
    "            decoder_input  \n",
    "    \n",
    "    # update weights after finish forward 1 batch\n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optim.step()\n",
    "    decoder_optim.step()\n",
    "    \n",
    "    return loss.data / de_time_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder, decoder, epochs, train_loader, test_loader, time_step, learning_rate=0.01, teacher_forcing_ratio=0.5):\n",
    "        encoder_optim = optim.SGD(filter(lambda x: x.requires_grad, encoder.parameters()), lr=learning_rate)\n",
    "        decoder_optim = optim.SGD(filter(lambda x: x.requires_grad, decoder.parameters()), lr=learning_rate)\n",
    "        \n",
    "        criterion = nn.NLLLoss()\n",
    "        for epoch in range(epochs):\n",
    "            print_loss_total = 0\n",
    "            for batch_x, batch_y in train_loader:\n",
    "                loss = batch_train(batch_x, batch_y, encoder, decoder, encoder_optim, decoder_optim, criterion, time_step, teacher_forcing_ratio)\n",
    "                print_loss_total += loss\n",
    "            print('epochs: '+str(epoch))\n",
    "            print('total loss: '+str(print_loss_total))\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0\n",
      "total loss: tensor(3.3093)\n",
      "\n",
      "epochs: 1\n",
      "total loss: tensor(3.5457)\n",
      "\n",
      "epochs: 2\n",
      "total loss: tensor(3.3186)\n",
      "\n",
      "epochs: 3\n",
      "total loss: tensor(3.0699)\n",
      "\n",
      "epochs: 4\n",
      "total loss: tensor(3.2578)\n",
      "\n",
      "epochs: 5\n",
      "total loss: tensor(3.1709)\n",
      "\n",
      "epochs: 6\n",
      "total loss: tensor(3.1182)\n",
      "\n",
      "epochs: 7\n",
      "total loss: tensor(2.9570)\n",
      "\n",
      "epochs: 8\n",
      "total loss: tensor(2.8541)\n",
      "\n",
      "epochs: 9\n",
      "total loss: tensor(2.7336)\n",
      "\n",
      "epochs: 10\n",
      "total loss: tensor(2.8898)\n",
      "\n",
      "epochs: 11\n",
      "total loss: tensor(2.7830)\n",
      "\n",
      "epochs: 12\n",
      "total loss: tensor(2.6468)\n",
      "\n",
      "epochs: 13\n",
      "total loss: tensor(2.8635)\n",
      "\n",
      "epochs: 14\n",
      "total loss: tensor(2.6827)\n",
      "\n",
      "epochs: 15\n",
      "total loss: tensor(2.9227)\n",
      "\n",
      "epochs: 16\n",
      "total loss: tensor(2.8652)\n",
      "\n",
      "epochs: 17\n",
      "total loss: tensor(2.7276)\n",
      "\n",
      "epochs: 18\n",
      "total loss: tensor(2.7731)\n",
      "\n",
      "epochs: 19\n",
      "total loss: tensor(2.7706)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_num = int(len(pairs)*0.9)\n",
    "train_loader = torch.utils.data.DataLoader(pairs[:train_num], \n",
    "    batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(pairs[train_num:], \n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "epochs = 20\n",
    "train(encoder, decoder, epochs, train_loader, test_loader, time_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_conda",
   "language": "python",
   "name": "torch_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
